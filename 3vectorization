#Prompt: Implement text vectorization using pytorch and adapt to the dataset.

import torch
from torch.nn.utils.rnn import pad_sequence

# Tokenize the text data
def tokenize(text):
    return text.split()

# Build vocabulary from the dataset
def build_vocab(text_data):
    vocab = {}
    idx = 1  # start indexing from 1
    for text in text_data:
        for token in tokenize(text):
            if token not in vocab:
                vocab[token] = idx
                idx += 1
    return vocab

# Vectorize the text using the vocabulary
def vectorize_layer(text, vocab):
    return torch.tensor([vocab[token] for token in tokenize(text) if token in vocab], dtype=torch.long)

# Apply the steps to the dataset
text_data = df['v2'].tolist()
vocab = build_vocab(text_data)

# Vectorize all text data
vectorized_texts = [vectorize_layer(text, vocab) for text in text_data]

# Pad sequences to ensure uniform length
padded_texts = pad_sequence(vectorized_texts, batch_first=True)

# Display the shape of the padded tensor
padded_texts.shape

# prompt: Visualize and compare one sentence from the raw data and vectorized data using def vectorize_layer

# USING PYTORCH

# Select a sentence from the raw data
sentence = df['v2'][0]

# Vectorize the sentence
vectorized_sentence = vectorize_layer(sentence, vocab)

# Print the raw sentence
print("Raw sentence:", sentence)

# Print the vectorized sentence
print("Vectorized sentence:", vectorized_sentence)

# prompt: Vector representation of the word 'movie' using pytorch

# USING PYTORCH

# Get the vector representation of the word 'movie'
movie_vector = vectorize_layer("movie", vocab)

# Print the vector
print("Vector representation of 'movie':", movie_vector)
